{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CDeep3M-V2-RetrainingGUI.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j3VNwQz5dZh0",
        "colab_type": "text"
      },
      "source": [
        "# <font color='#000FF'> **CDeep3M2** </font>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pXbJz-P7zdA1",
        "colab_type": "code",
        "cellView": "both",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 538
        },
        "outputId": "55311ef5-3774-4f4b-b36a-9ac09a5f1ea6"
      },
      "source": [
        "#@title # <==== Click 'Run Cell' for CDeep3M Installation\n",
        "#@markdown (Time est.: 20-30min)\n",
        "\n",
        "#@markdown A hardware check will initially performed to ensure the \n",
        "#@markdown runtime envirnment has sufficient GPU vRAM, \n",
        "#@markdown otherwise please click: Runtime -> Factory Reset\n",
        "#################\n",
        "# Prep\n",
        "#################\n",
        "\n",
        "!mkdir -p /home/\n",
        "%cd /home/\n",
        "# Get the repo\n",
        "!git clone https://github.com/haberlmatt/cdeep3m-colab.git\n",
        "\n",
        "# Install CDeep3M - Packaged into a installer file\n",
        "!chmod 777 /home/cdeep3m-colab/*\n",
        "\n",
        "# Make sure enough GPU memory available on this instance\n",
        "!python /home/cdeep3m-colab/tests/pythontest_GPUmem.py\n",
        "#!nvidia-smi\n",
        "\n",
        "##################################\n",
        "# Run CDeep3M installation\n",
        "##################################\n",
        "!/bin/bash /home/cdeep3m-colab/CDeep3M_V2_colab-installer.sh > /home/CDeep3m_installation.log\n",
        "\n",
        "#################\n",
        "# Set Environment\n",
        "#################\n",
        "import os\n",
        "os.environ['PATH'] += \":/home/nd_sense/caffe_nd_sense_segmentation/\"\n",
        "os.environ['CAFFE_PATH'] = \"/home/nd_sense/caffe_nd_sense_segmentation/\"\n",
        "os.environ['PYTHONPATH'] = \"/home/nd_sense/caffe_nd_sense_segmentation/distribute/python/\"\n",
        "os.environ['PATH'] += \":/home/cdeep3m/\"\n",
        "\n",
        "print(\"CDeep3M installation completed \\n   Runnning CDeep3M Version\")\n",
        "!cat /home/cdeep3m/VERSION\n",
        "print(\"\\nPlease see https://github.com/haberlmatt/cdeep3m-colab for further information on using CDeep3M\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/home\n",
            "Cloning into 'cdeep3m-colab'...\n",
            "remote: Enumerating objects: 137, done.\u001b[K\n",
            "remote: Counting objects: 100% (137/137), done.\u001b[K\n",
            "remote: Compressing objects: 100% (128/128), done.\u001b[K\n",
            "remote: Total 137 (delta 79), reused 9 (delta 7), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (137/137), 35.11 KiB | 473.00 KiB/s, done.\n",
            "Resolving deltas: 100% (79/79), done.\n",
            "python3: can't open file '/home/cdeep3m-colab/pythontest_GPUmem.py': [Errno 2] No such file or directory\n",
            "Extracting templates from packages: 100%\n",
            "Cloning into 'bats-core'...\n",
            "remote: Enumerating objects: 2102, done.\u001b[K\n",
            "remote: Total 2102 (delta 0), reused 0 (delta 0), pack-reused 2102\u001b[K\n",
            "Receiving objects: 100% (2102/2102), 598.42 KiB | 1.54 MiB/s, done.\n",
            "Resolving deltas: 100% (1147/1147), done.\n",
            "\u001b[31mERROR: fastai 0.7.0 has requirement torch<0.4, but you'll have torch 1.4.0 which is incompatible.\u001b[0m\n",
            "sed: can't read /usr/bin/pip3: No such file or directory\n",
            "Cloning into 'caffe_nd_sense_segmentation'...\n",
            "remote: Enumerating objects: 26205, done.\u001b[K\n",
            "remote: Total 26205 (delta 0), reused 0 (delta 0), pack-reused 26205\u001b[K\n",
            "Receiving objects: 100% (26205/26205), 35.44 MiB | 18.57 MiB/s, done.\n",
            "Resolving deltas: 100% (17123/17123), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vnnls_aWQU01",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 40
        },
        "outputId": "d74a2324-d4fc-4960-bf5c-0735cc7d4100"
      },
      "source": [
        "!ls /home"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CDeep3m_installation.log\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ykcqRXUsl9Qu",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title # CDeep3M Colab -- Retrain model GUI\n",
        "#@markdown Simple user interface to run CDeep3M on Colab\n",
        "#@markdown Please make sure to run installation above first\n",
        "\n",
        "#@markdown ### Please pick a DOI from the CDeep3M model zoo\n",
        "#@markdown #### See: http://www.cellimagelibrary.org/cdeep3m\n",
        "Model_DOI = 'https://doi.org/10.7295/W9CDEEP3M50687' #@param {type:\"string\"}\n",
        "#@markdown ### Insert Path to your training images here:\n",
        "Image_Path = '/home/cdeep3m/mito_testsample/training/images' #@param {type:\"string\"}\n",
        "#@markdown ### Insert Path to your training labels here:\n",
        "Label_Path = '/home/cdeep3m/mito_testsample/training/labels' #@param {type:\"string\"}\n",
        "\n",
        "secondary_augm=int(-1)\n",
        "tertiary_augm=0\n",
        "# Hidden feature, uncomment following two lines to set secondary and tertiary augmentations:\n",
        "#secondary_augm = -1 #@param {type:\"slider\", min:-1, max:10, step:1}\n",
        "#tertiary_augm = 0 #@param {type:\"slider\", min:0, max:10, step:1}\n",
        "\n",
        "\n",
        "#@markdown ### How many training iterations:\n",
        "num_iter = 1000 #@param {type:\"slider\", min:100, max:5000, step:100}\n",
        "#@markdown ### Train network seeing 1 frame, 3 frames, 5 frames:\n",
        "train_1fm = True #@param {type:\"boolean\"}\n",
        "train_3fm = True #@param {type:\"boolean\"}\n",
        "train_5fm = True #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown ### Enter a path where files are written:\n",
        "output_path = \"/home/retrained_model/\" #@param {type:\"string\"}\n",
        "#@markdown ---\n",
        "\n",
        "import os\n",
        "if Model_DOI is not None and Model_DOI !='':    \n",
        "    %cd /home/    \n",
        "    !rm -r /home/trainedmodel\n",
        "    !mkdir /home/trainedmodel/\n",
        "    cmd=str(\"wget -O model_download \" + Model_DOI)\n",
        "    print(cmd)   \n",
        "    os.system(cmd)\n",
        "    #!wget -O \"model_download\" Model_DOI\n",
        "    !tar -xvf model_download -C /home/trainedmodel/\n",
        "    d = '/home/trainedmodel/'\n",
        "    model_path = [os.path.join(d, o) for o in os.listdir(d) \n",
        "                        if os.path.isdir(os.path.join(d,o))]\n",
        "else:\n",
        "    print('Provide a model')\n",
        "\n",
        "# Convert into 1fm, 3fm and 5fm selection into string\n",
        "fm_list = [str('1fm' * train_1fm), str('3fm' * train_3fm), str('5fm' * train_5fm)]\n",
        "filtered_fm = filter(lambda x: x != \"\", fm_list)\n",
        "combined_fm = list(filtered_fm)\n",
        "fm_string = ','.join(combined_fm)\n",
        "if fm_string is not None and fm_string !='':\n",
        "    print('Running: ' + fm_string)\n",
        "else:\n",
        "    print('Provide a selection for which fm model to run')\n",
        "\n",
        "print('Starting to run ...')\n",
        "# Preprocess Training Data\n",
        "augmented_path='/home/augmented_data/'\n",
        "exec_command=str('PreprocessTraining.py ' + Image_Path + ' ' + Label_Path + ' ' + str(secondary_augm) + ' ' + str(tertiary_augm) + ' ' + augmented_path) \n",
        "print(exec_command)\n",
        "!{exec_command}\n",
        "# currently removed --models ' + fm_string + ' '\n",
        "exec_command=str('runtraining.sh ' + '--numiterations ' + str(num_iter)  + ' ' + augmented_path +  ' ' + output_path) \n",
        "print(exec_command)\n",
        "!{exec_command}\n",
        "\n",
        "if train_1fm == True:\n",
        "    exec_command=str('PlotValidation.py ' + os.path.join(output_path, '1fm','log'))\n",
        "    !{exec_command}\n",
        "if train_3fm == True:\n",
        "    exec_command=str('PlotValidation.py ' + os.path.join(output_path, '3fm','log'))\n",
        "    !{exec_command}\n",
        "if train_3fm == True:\n",
        "    exec_command=str('PlotValidation.py ' + os.path.join(output_path, '5fm','log'))\n",
        "    !{exec_command}"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}